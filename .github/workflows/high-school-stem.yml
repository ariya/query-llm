name: High-school STEM

on: [workflow_dispatch, push, pull_request]

jobs:

  high-school-stem:
    runs-on: ubuntu-22.04
    timeout-minutes: 5
    strategy:
      max-parallel: 3
      fail-fast: false
      matrix:
        model:
          - meta-llama/llama-3.2-3b-instruct             # $0.0300/$0.0300 [ 128K]
          - google/gemma-3-4b-it                         # $0.0200/$0.0400 [ 128K]
          - meta-llama/llama-3.1-8b-instruct             # $0.0200/$0.0500 [ 128K]
          - mistralai/mistral-7b-instruct-v0.3           # $0.0550/$0.0550 [  32K]
          - mistralai/mistral-nemo                       # $0.1300/$0.1300 [ 128K]
          - amazon/nova-micro-v1                         # $0.0350/$0.1400 [ 128K]
          - qwen/qwen-turbo                              # $0.0500/$0.2000 [1000K]
          - amazon/nova-lite-v1                          # $0.0600/$0.2400 [ 300K]
          - mistralai/mixtral-8x7b-instruct              # $0.2400/$0.2400 [  32K]
          - qwen/qwen-2.5-7b-instruct                    # $0.2700/$0.2700 [ 128K]
          - meta-llama/llama-4-scout                     # $0.0800/$0.3000 [ 320K]
          - mistralai/mistral-small-3.1-24b-instruct     # $0.1000/$0.3000 [ 128K]
          - google/gemini-2.0-flash-001                  # $0.1000/$0.4000 [1000K]
          - openai/gpt-4.1-nano                          # $0.1000/$0.4000 [1000K]
          - meta-llama/llama-3.3-70b-instruct            # $0.1300/$0.4000 [ 128K]
    steps:
      - uses: actions/checkout@v4

      - run: ./query-llm.js tests/high-school-stem.txt
        env:
          LLM_API_BASE_URL: ${{ secrets.LLM_API_BASE_URL }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_CHAT_MODEL: ${{ matrix.model }}
