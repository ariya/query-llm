name: Prepare Small LLM
description: Download small LLM and launch it
runs:
  using: composite
  steps:
    - name: Download and unpack llama.cpp
      shell: bash
      run: |
        curl -OL https://github.com/ggerganov/llama.cpp/releases/download/b4003/llama-b4003-bin-ubuntu-x64.zip
        unzip llama-b4003-bin-ubuntu-x64.zip

    - name: Launch llama.cpp
      shell: bash
      run: ./build/bin/llama-server -c 4096 --hf-repo unsloth/SmolLM2-1.7B-Instruct-GGUF --hf-file SmolLM2-1.7B-Instruct-Q6_K.gguf &

    - name: Wait until it is ready
      shell: bash
      run: while ! curl -s 'http://localhost:8080/health' | grep 'ok'; do sleep 1; done
